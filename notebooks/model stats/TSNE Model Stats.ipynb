{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from .ext_imports import *\n",
    "activity = 'Firemaking'\n",
    "df, formatter = get_dataframe(activity, limit=2500, aggregate=True, skill_type=SkillType.LEVELS)\n",
    "\n",
    "X = df.drop(columns=['Banned', 'pid'])\n",
    "y = df['Banned']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T12:44:15.473099800Z",
     "start_time": "2024-05-18T12:44:09.471107300Z"
    }
   },
   "id": "e135f0541884ce08",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T20:21:56.121860600Z",
     "start_time": "2024-05-17T20:21:56.114850400Z"
    }
   },
   "id": "339e29ed650b1bef",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5ee9745822f01bf",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T20:21:56.139848900Z",
     "start_time": "2024-05-17T20:21:56.121860600Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "standard_features = formatter.agg_skills + formatter.agg_minigames\n",
    "robust_features = formatter.extra_features #[]    # Assume these have outliers\n",
    "minmax_features = formatter.live_skills  #[]  # Assume these need scaling between 0 and 1\n",
    "minmax_features_2 = formatter.live_minigames #[] \n",
    "\n",
    "# Creating the ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('std', StandardScaler(), standard_features),\n",
    "        ('robust', RobustScaler(), robust_features),\n",
    "        ('minmax', MinMaxScaler(), minmax_features),\n",
    "        ('minmax_2', MinMaxScaler(), minmax_features_2),\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline as ImblearnPipeline\n",
    "from rs_data import (PCA, TSNE, UMAP)\n",
    "\n",
    "# Create an imblearn pipeline with SMOTE\n",
    "pipeline = ImblearnPipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),  # SMOTE applied only during training\n",
    "    ('PCA', TSNE(n_components=3)),\n",
    "    ('classifier', ExtraTreesClassifier())\n",
    "])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-17T20:21:56.168850400Z",
     "start_time": "2024-05-17T20:21:56.137849Z"
    }
   },
   "id": "initial_id",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1745, number of negative: 1745\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.087353 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 3490, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 1745, number of negative: 1745\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.098336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 3490, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Classifier list\n",
    "classifiers = [\n",
    "    (\"RandomForest\", RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)),\n",
    "    (\"ExtraTrees\", ExtraTreesClassifier(n_estimators=100, random_state=42, n_jobs=-1)),\n",
    "    (\"GradientBoosting\", GradientBoostingClassifier(random_state=42)),  # Does not support n_jobs\n",
    "    (\"SVM\", SVC(probability=True, random_state=42)),  # Does not support n_jobs\n",
    "    (\"LogisticRegression\", LogisticRegression(random_state=42, n_jobs=-1)),\n",
    "    (\"LGBMClassifier\", LGBMClassifier(random_state=42, n_jobs=-1)),\n",
    "    (\"XGBClassifier\", XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42, n_jobs=-1))\n",
    "]\n",
    "\n",
    "# Creating the preprocessing pipeline\n",
    "preprocessor = StandardScaler()\n",
    "\n",
    "# Results DataFrame\n",
    "\n",
    "rows = []\n",
    "\n",
    "pca_components = [\n",
    "    2, 10, 30, 50\n",
    "]\n",
    "\n",
    "tsne_perplexities = [\n",
    "    30\n",
    "]\n",
    "\n",
    "for tsne_perplexity in tsne_perplexities:\n",
    "    for pca_n_components in pca_components:\n",
    "        for name, classifier in classifiers:\n",
    "            # Create the pipeline\n",
    "            pipeline = ImblearnPipeline([\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('smote', SMOTE(random_state=42)),\n",
    "                ('PCA', PCA(n_components=pca_n_components)),\n",
    "                ('TSNE', TSNE(n_components=2,perplexity=tsne_perplexity)),\n",
    "                ('classifier', classifier)\n",
    "            ])\n",
    "        \n",
    "            # Calculate scores\n",
    "            accuracy_scores = cross_val_score(pipeline, X, y, cv=cv, scoring='accuracy')\n",
    "            y_pred_proba  = cross_val_predict(pipeline, X, y, cv=cv)\n",
    "            \n",
    "            y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "            accuracy_per_class = [\n",
    "                accuracy_score(y == k, y_pred == k) for k in [0, 1]\n",
    "            ]\n",
    "            roc_auc = roc_auc_score(y, y_pred)\n",
    "            \n",
    "            \n",
    "            recall_per_class = recall_score(y, y_pred, average=None)\n",
    "        \n",
    "            # Confusion matrix\n",
    "            conf_matrix = confusion_matrix(y, y_pred)\n",
    "            \n",
    "            data = {\n",
    "                'Classifier': [name],\n",
    "                'PCA_N_COMPONENTS': pca_n_components,\n",
    "                'TSNE_Perplexity': tsne_perplexity,\n",
    "                'Accuracy': [np.mean(accuracy_scores)],\n",
    "                'Recall_0': [recall_per_class[0]],\n",
    "                'Recall_1': [recall_per_class[1]],\n",
    "                'Accuracy_0': [accuracy_per_class[0]],\n",
    "                'Accuracy_1': [accuracy_per_class[1]],\n",
    "                'ROC-AUC': [roc_auc],\n",
    "                'Matrix': [conf_matrix.tolist()]\n",
    "            }\n",
    "            rows.append(\n",
    "                (name,pca_n_components,tsne_perplexities, np.mean(accuracy_scores), \n",
    "                 recall_per_class[0], recall_per_class[1], \n",
    "                 accuracy_per_class[0], accuracy_per_class[1], \n",
    "                 roc_auc, conf_matrix.tolist() )\n",
    "            )\n",
    "    \n",
    "results = pd.DataFrame(rows, columns=['Classifier', 'PCA_N_COMPONENTS', 'TSNE_Perplexity', 'Accuracy', 'Recall_0', 'Recall_1', 'Accuracy_0', 'Accuracy_1', 'ROC-AUC', 'Matrix' ])\n",
    "# Print the results sorted by 'Accuracy' and 'Recall'\n",
    "results.sort_values(by=['Accuracy', 'Recall_1'], ascending=False, inplace=True)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-05-17T20:21:56.153849400Z"
    }
   },
   "id": "8036462605d09746",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stacked models\n",
    "\n",
    "\n",
    "- High performance for recall and accuracy on class 1 (but performs well on both)\n",
    "    - SVM,50\n",
    "    - LogisticRegression,30\n",
    "\n",
    "- High performance for recall and accuracy on class 0\n",
    "    - ExtraTrees,50\n",
    "    - LGBMClassifier,30\n",
    "\n",
    "---\n",
    "\n",
    "# Level 0 Stacked Models\n",
    "\n",
    "| Classifier         | PCA_N_COMPONENTS | Accuracy | Recall_0 | Recall_1 | Accuracy_0 | Accuracy_1 | ROC-AUC  | Matrix                         |\n",
    "|--------------------|------------------|----------|----------|----------|------------|------------|----------|--------------------------------|\n",
    "| SVM                | 50               | 0.8048   | 0.815765 | 0.764151 | 0.8092     | 0.8092     | 0.789958 | [[1780, 402], [75, 243]]       |\n",
    "| LogisticRegression | 30               | 0.7876   | 0.805225 | 0.710692 | 0.7932     | 0.7932     | 0.757958 | [[1757, 425], [92, 226]]       |\n",
    "| ExtraTrees         | 50               | 0.8732   | 0.942713 | 0.396226 | 0.8732     | 0.8732     | 0.669470 | [[2057, 125], [192, 126]]      |\n",
    "| LGBMClassifier     | 30               | 0.8548   | 0.890926 | 0.559748 | 0.8488     | 0.8488     | 0.725337 | [[1944, 238], [140, 178]]      |\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34fb52d2f2943838"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
