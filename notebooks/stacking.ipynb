{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "          pid  Banned  updates  activescrapes  inactivescrapes  \\\n0      170698   False       37             28                9   \n1       80833   False       71             67                4   \n2     3804178    True       19              4               15   \n3      682311    True       45             40                5   \n4     1096481   False       71             70                1   \n...       ...     ...      ...            ...              ...   \n2495   339693   False       57             21               36   \n2496   105584   False       72             67                5   \n2497   182610   False       72             65                7   \n2498    75002   False       72             71                1   \n2499   106360   False       31             19               12   \n\n      shortestinactivity  shortestactivity  longestinactivity  \\\n0                      1                 1                  6   \n1                      1                 3                  2   \n2                      7                 1                  8   \n3                      5                 0                  5   \n4                      1                 0                  1   \n...                  ...               ...                ...   \n2495                   1                 1                 11   \n2496                   2                 1                  3   \n2497                   1                 1                  1   \n2498                   1                 0                  1   \n2499                   1                 2                  7   \n\n      longestactivity  Overall_live  ...  Vardorvis_aggregate  \\\n0                   9    2236452139  ...                  0.0   \n1                  53     601621625  ...                  0.0   \n2                   1     171624284  ...                  0.0   \n3                   0     252826786  ...                  0.0   \n4                   0     687382853  ...                  0.0   \n...               ...           ...  ...                  ...   \n2495               11     177086291  ...                  0.0   \n2496                1     319339186  ...                  0.0   \n2497               23     216491210  ...                  0.0   \n2498                0     427903760  ...                  0.0   \n2499                5     215829383  ...                  0.0   \n\n      Venenatis_aggregate  Vet'ion_aggregate  Vorkath_aggregate  \\\n0                     8.0                0.0             4115.0   \n1                     0.0                0.0                0.0   \n2                     0.0                0.0                0.0   \n3                     0.0                0.0                0.0   \n4                     0.0                0.0                0.0   \n...                   ...                ...                ...   \n2495                  0.0                0.0                0.0   \n2496                  2.0                0.0                0.0   \n2497                  0.0                0.0               84.0   \n2498                  0.0                0.0                0.0   \n2499                  0.0                0.0                7.0   \n\n      Wintertodt_aggregate  Zalcano_aggregate  Zulrah_aggregate  \\\n0                   6342.0              251.0            3117.0   \n1                   5752.0                0.0               0.0   \n2                    577.0                0.0               0.0   \n3                   6254.0                0.0               0.0   \n4                   3588.0                0.0               0.0   \n...                    ...                ...               ...   \n2495                  83.0                0.0               0.0   \n2496                 101.0                0.0               0.0   \n2497                 287.0               50.0               0.0   \n2498                  53.0                0.0               0.0   \n2499                 183.0                0.0               0.0   \n\n      Colosseum Glory_aggregate  Deadman Points_aggregate  \\\n0                             0                         0   \n1                             0                         0   \n2                             0                         0   \n3                             0                         0   \n4                             0                         0   \n...                         ...                       ...   \n2495                          0                         0   \n2496                          0                         0   \n2497                          0                         0   \n2498                          0                         0   \n2499                          0                         0   \n\n      League Points_aggregate  \n0                           0  \n1                           0  \n2                           0  \n3                           0  \n4                           0  \n...                       ...  \n2495                        0  \n2496                        0  \n2497                        0  \n2498                        0  \n2499                        0  \n\n[2500 rows x 209 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pid</th>\n      <th>Banned</th>\n      <th>updates</th>\n      <th>activescrapes</th>\n      <th>inactivescrapes</th>\n      <th>shortestinactivity</th>\n      <th>shortestactivity</th>\n      <th>longestinactivity</th>\n      <th>longestactivity</th>\n      <th>Overall_live</th>\n      <th>...</th>\n      <th>Vardorvis_aggregate</th>\n      <th>Venenatis_aggregate</th>\n      <th>Vet'ion_aggregate</th>\n      <th>Vorkath_aggregate</th>\n      <th>Wintertodt_aggregate</th>\n      <th>Zalcano_aggregate</th>\n      <th>Zulrah_aggregate</th>\n      <th>Colosseum Glory_aggregate</th>\n      <th>Deadman Points_aggregate</th>\n      <th>League Points_aggregate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>170698</td>\n      <td>False</td>\n      <td>37</td>\n      <td>28</td>\n      <td>9</td>\n      <td>1</td>\n      <td>1</td>\n      <td>6</td>\n      <td>9</td>\n      <td>2236452139</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>8.0</td>\n      <td>0.0</td>\n      <td>4115.0</td>\n      <td>6342.0</td>\n      <td>251.0</td>\n      <td>3117.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>80833</td>\n      <td>False</td>\n      <td>71</td>\n      <td>67</td>\n      <td>4</td>\n      <td>1</td>\n      <td>3</td>\n      <td>2</td>\n      <td>53</td>\n      <td>601621625</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5752.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3804178</td>\n      <td>True</td>\n      <td>19</td>\n      <td>4</td>\n      <td>15</td>\n      <td>7</td>\n      <td>1</td>\n      <td>8</td>\n      <td>1</td>\n      <td>171624284</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>577.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>682311</td>\n      <td>True</td>\n      <td>45</td>\n      <td>40</td>\n      <td>5</td>\n      <td>5</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>252826786</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>6254.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1096481</td>\n      <td>False</td>\n      <td>71</td>\n      <td>70</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>687382853</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3588.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2495</th>\n      <td>339693</td>\n      <td>False</td>\n      <td>57</td>\n      <td>21</td>\n      <td>36</td>\n      <td>1</td>\n      <td>1</td>\n      <td>11</td>\n      <td>11</td>\n      <td>177086291</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>83.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2496</th>\n      <td>105584</td>\n      <td>False</td>\n      <td>72</td>\n      <td>67</td>\n      <td>5</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>319339186</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>101.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2497</th>\n      <td>182610</td>\n      <td>False</td>\n      <td>72</td>\n      <td>65</td>\n      <td>7</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>23</td>\n      <td>216491210</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>84.0</td>\n      <td>287.0</td>\n      <td>50.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2498</th>\n      <td>75002</td>\n      <td>False</td>\n      <td>72</td>\n      <td>71</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>427903760</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>53.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2499</th>\n      <td>106360</td>\n      <td>False</td>\n      <td>31</td>\n      <td>19</td>\n      <td>12</td>\n      <td>1</td>\n      <td>2</td>\n      <td>7</td>\n      <td>5</td>\n      <td>215829383</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>183.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2500 rows Ã— 209 columns</p>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rs_data import get_dataframe, SkillType, evaluate_model\n",
    "\n",
    "activity = 'Firemaking'\n",
    "df, formatter = get_dataframe(activity, limit=2500, aggregate=True, skill_type=SkillType.EXPERIENCE)\n",
    "\n",
    "X = df.drop(columns=['Banned', 'pid'])\n",
    "y = df['Banned']\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T20:24:54.975450500Z",
     "start_time": "2024-05-17T20:24:54.420855Z"
    }
   },
   "id": "e135f0541884ce08",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "# Sampling \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, SVMSMOTE, KMeansSMOTE\n",
    "# Models\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import recall_score, accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T20:24:54.975450500Z",
     "start_time": "2024-05-17T20:24:54.970452700Z"
    }
   },
   "id": "339e29ed650b1bef",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5ee9745822f01bf",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T20:24:55.007845800Z",
     "start_time": "2024-05-17T20:24:54.974451100Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "standard_features = formatter.agg_skills + formatter.agg_minigames\n",
    "robust_features = formatter.extra_features #[]    # Assume these have outliers\n",
    "minmax_features = formatter.live_skills  #[]  # Assume these need scaling between 0 and 1\n",
    "minmax_features_2 = formatter.live_minigames #[] \n",
    "\n",
    "# Creating the ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('std', StandardScaler(), standard_features),\n",
    "        ('robust', RobustScaler(), robust_features),\n",
    "        ('minmax', MinMaxScaler(), minmax_features),\n",
    "        ('minmax_2', MinMaxScaler(), minmax_features_2),\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline as ImblearnPipeline\n",
    "from rs_data import (PCA, TSNE, UMAP)\n",
    "\n",
    "# Create an imblearn pipeline with SMOTE\n",
    "pipeline = ImblearnPipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),  # SMOTE applied only during training\n",
    "    ('PCA', TSNE(n_components=3)),\n",
    "    ('classifier', ExtraTreesClassifier())\n",
    "])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-17T20:24:55.038365700Z",
     "start_time": "2024-05-17T20:24:54.988965200Z"
    }
   },
   "id": "initial_id",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Classifier': ['RandomForest'], 'Accuracy': [0.8160000000000001], 'Recall_0': [0.8570119156736938], 'Recall_1': [0.5440251572327044], 'Accuracy_0': [0.8172], 'Accuracy_1': [0.8172], 'ROC-AUC': [0.7005185364531991], 'Matrix': [[[1870, 312], [145, 173]]]}\n",
      "{'Classifier': ['ExtraTrees'], 'Accuracy': [0.828], 'Recall_0': [0.8661778185151238], 'Recall_1': [0.5440251572327044], 'Accuracy_0': [0.8252], 'Accuracy_1': [0.8252], 'ROC-AUC': [0.7051014878739141], 'Matrix': [[[1890, 292], [145, 173]]]}\n",
      "{'Classifier': ['GradientBoosting'], 'Accuracy': [0.76], 'Recall_0': [0.773602199816682], 'Recall_1': [0.6477987421383647], 'Accuracy_0': [0.7576], 'Accuracy_1': [0.7576], 'ROC-AUC': [0.7107004709775234], 'Matrix': [[[1688, 494], [112, 206]]]}\n",
      "{'Classifier': ['SVM'], 'Accuracy': [0.732], 'Recall_0': [0.7373968835930339], 'Recall_1': [0.7012578616352201], 'Accuracy_0': [0.7328], 'Accuracy_1': [0.7328], 'ROC-AUC': [0.719327372614127], 'Matrix': [[[1609, 573], [95, 223]]]}\n",
      "{'Classifier': ['LogisticRegression'], 'Accuracy': [0.6852], 'Recall_0': [0.6782768102658112], 'Recall_1': [0.720125786163522], 'Accuracy_0': [0.6836], 'Accuracy_1': [0.6836], 'ROC-AUC': [0.6992012982146666], 'Matrix': [[[1480, 702], [89, 229]]]}\n",
      "[LightGBM] [Info] Number of positive: 1745, number of negative: 1745\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081912 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 3490, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 1745, number of negative: 1745\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081427 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 3490, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 1746, number of negative: 1746\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.078394 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 3492, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 1746, number of negative: 1746\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.099426 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 3492, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 1746, number of negative: 1746\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000288 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 3492, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 1745, number of negative: 1745\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.080231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 3490, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 1745, number of negative: 1745\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082939 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 3490, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 1746, number of negative: 1746\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.074430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 3492, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 1746, number of negative: 1746\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040127 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 3492, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 1746, number of negative: 1746\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.110227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 3492, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Classifier list\n",
    "classifiers = [\n",
    "    (\"RandomForest\", RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)),\n",
    "    (\"ExtraTrees\", ExtraTreesClassifier(n_estimators=100, random_state=42, n_jobs=-1)),\n",
    "    (\"GradientBoosting\", GradientBoostingClassifier(random_state=42)),  # Does not support n_jobs\n",
    "    (\"SVM\", SVC(probability=True, random_state=42)),  # Does not support n_jobs\n",
    "    (\"LogisticRegression\", LogisticRegression(random_state=42, n_jobs=-1)),\n",
    "    (\"LGBMClassifier\", LGBMClassifier(random_state=42, n_jobs=-1)),\n",
    "    (\"XGBClassifier\", XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42, n_jobs=-1))\n",
    "]\n",
    "\n",
    "# Creating the preprocessing pipeline\n",
    "preprocessor = StandardScaler()\n",
    "\n",
    "# Results DataFrame\n",
    "\n",
    "rows = []\n",
    "\n",
    "n_component_list = [6, 15, 35, 50]\n",
    "\n",
    "for n_c in n_component_list:\n",
    "    for name, classifier in classifiers:\n",
    "        # Create the pipeline\n",
    "        pipeline = ImblearnPipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('smote', SMOTE(random_state=42)),\n",
    "            ('pca', PCA(n_components=6)),\n",
    "            ('classifier', classifier)\n",
    "        ])\n",
    "    \n",
    "        # Calculate scores\n",
    "        accuracy_scores = cross_val_score(pipeline, X, y, cv=cv, scoring='accuracy')\n",
    "        y_pred_proba  = cross_val_predict(pipeline, X, y, cv=cv)\n",
    "        \n",
    "        y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "        accuracy_per_class = [\n",
    "            accuracy_score(y == k, y_pred == k) for k in [0, 1]\n",
    "        ]\n",
    "        roc_auc = roc_auc_score(y, y_pred)\n",
    "        \n",
    "        \n",
    "        recall_per_class = recall_score(y, y_pred, average=None)\n",
    "    \n",
    "        # Confusion matrix\n",
    "        conf_matrix = confusion_matrix(y, y_pred)\n",
    "        \n",
    "        data = {\n",
    "            'Classifier': [name],\n",
    "            'Accuracy': [np.mean(accuracy_scores)],\n",
    "            'Recall_0': [recall_per_class[0]],\n",
    "            'Recall_1': [recall_per_class[1]],\n",
    "            'Accuracy_0': [accuracy_per_class[0]],\n",
    "            'Accuracy_1': [accuracy_per_class[1]],\n",
    "            'ROC-AUC': [roc_auc],\n",
    "            'Matrix': [conf_matrix.tolist()]\n",
    "        }\n",
    "        print(data)\n",
    "        rows.append(\n",
    "            (name, np.mean(accuracy_scores), \n",
    "             recall_per_class[0], recall_per_class[1], \n",
    "             accuracy_per_class[0], accuracy_per_class[1], \n",
    "             roc_auc, conf_matrix.tolist() )\n",
    "        )\n",
    "    \n",
    "\n",
    "results = pd.DataFrame(rows, columns=['Classifier', 'Accuracy', 'Recall_0', 'Recall_1', 'Accuracy_0', 'Accuracy_1', 'ROC-AUC', 'Matrix' ])\n",
    "# Print the results sorted by 'Accuracy' and 'Recall'\n",
    "results.sort_values(by=['Accuracy', 'Recall_1'], ascending=False, inplace=True)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-05-17T20:24:55.004846500Z"
    }
   },
   "id": "a623621f2b272771"
  },
  {
   "cell_type": "markdown",
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 15]\n",
    "}\n",
    "\n",
    "# Setup cross-validation scheme\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Setup the GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=classifier, param_grid=param_grid, cv=cv)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validated score:\", grid_search.best_score_)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d1cebbec6e275ac"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import StackingClassifier, GradientBoostingClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "banned_class_models = [\n",
    "    ('svm_pca', Pipeline([\n",
    "        ('pca', PCA(n_components=50)),  # Include PCA as the first step\n",
    "        ('svm', SVC(probability=True, random_state=42))\n",
    "    ])),\n",
    "    ('log_regression_pca', Pipeline([\n",
    "        ('pca', PCA(n_components=30)),  # Include PCA as the first step\n",
    "        ('log_reg_algo', LogisticRegression(random_state=42, n_jobs=-1))\n",
    "    ])),\n",
    "    ('log_regression_pca', Pipeline([\n",
    "        ('pca', PCA(n_components=6)),  # Include PCA as the first step\n",
    "        ('log_reg_algo', LogisticRegression(random_state=42, n_jobs=-1))\n",
    "    ])),\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "unbanned_class_models = [\n",
    "    ('ExtraTrees_pca', Pipeline([\n",
    "        ('pca', PCA(n_components=50)),  # Include PCA as the first step\n",
    "        ('ExtraTrees', ExtraTreesClassifier(n_estimators=100, random_state=42, n_jobs=-1))\n",
    "    ])),\n",
    "    ('LGBM_pca', Pipeline([\n",
    "        ('pca', PCA(n_components=30)),  # Include PCA as the first step\n",
    "        ('LGBM', LGBMClassifier(random_state=42, n_jobs=-1))\n",
    "    ])),\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "    ('k-means', Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        \n",
    "        ('PCA', PCA(n_components=50)),\n",
    "        ('TSNE', TSNE(n_components=2)),\n",
    "        ('KMeans', KMeans(n_clusters=2))\n",
    "    ])),\n",
    "    \"\"\"\n",
    "\n",
    "# Define the base models for level 0\n",
    "level0 = [\n",
    "    #('gb', GradientBoostingClassifier(random_state=42))\n",
    "] + banned_class_models # +  unbanned_class_models\n",
    "\n",
    "# Define the meta model for level 1\n",
    "level1 = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the stacking ensemble\n",
    "model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5, stack_method='predict_proba')\n",
    "\n",
    "# Create a pipeline with preprocessing and the stacking model\n",
    "pipeline = ImblearnPipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),  # SMOTE applied only during training\n",
    "    ('stacking', model)\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "# Predictions and evaluation\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "6c3e2616a4e83b70",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# Cross-validation scores\n",
    "cv_scores = cross_val_score(pipeline, X, y, cv=5)\n",
    "print(\"Cross-validated Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean CV Accuracy:\", np.mean(cv_scores))\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "ab948451015f45b0",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SVMSMOTE\n",
    "\n",
    "Classification Report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "       False       0.94      0.98      0.96       443\n",
    "        True       0.73      0.53      0.61        57\n",
    "\n",
    "    accuracy                           0.92       500\n",
    "   macro avg       0.84      0.75      0.79       500\n",
    "weighted avg       0.92      0.92      0.92       500\n",
    "\n",
    "Confusion Matrix:\n",
    " [[432  11]\n",
    " [ 27  30]]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5021c3b1a47e5e42"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BorderlineSMOTE\n",
    "\n",
    "## Random Forest Level 1, 100 trees\n",
    "\n",
    "Classification Report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "       False       0.93      0.97      0.95       443\n",
    "        True       0.63      0.42      0.51        57\n",
    "\n",
    "    accuracy                           0.91       500\n",
    "   macro avg       0.78      0.69      0.73       500\n",
    "weighted avg       0.89      0.91      0.90       500\n",
    "\n",
    "Confusion Matrix:\n",
    " [[429  14]\n",
    " [ 33  24]]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cccd533ac5780b7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Default SMOTE\n",
    "\n",
    "## Random forest Level 1 , 100 trees\n",
    "\n",
    "\n",
    "Classification Report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "       False       0.93      0.97      0.95       443\n",
    "        True       0.67      0.46      0.54        57\n",
    "\n",
    "    accuracy                           0.91       500\n",
    "   macro avg       0.80      0.71      0.75       500\n",
    "weighted avg       0.90      0.91      0.90       500\n",
    "\n",
    "Cross-validated Accuracy Scores: [0.8   0.89  0.894 0.894 0.904]\n",
    "Mean CV Accuracy: 0.8764000000000001\n",
    "\n",
    "## Logistic_regression\n",
    "\n",
    "- Worse score, lower recall and accuracy.\n",
    "\n",
    "\n",
    "## SVC\n",
    "\n",
    "Classification Report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "       False       0.94      0.93      0.93       443\n",
    "        True       0.48      0.51      0.50        57\n",
    "\n",
    "    accuracy                           0.88       500\n",
    "   macro avg       0.71      0.72      0.71       500\n",
    "weighted avg       0.88      0.88      0.88       500\n",
    "\n",
    "Confusion Matrix:\n",
    " [[412  31]\n",
    " [ 28  29]]\n",
    " \n",
    "\n",
    "## ExtraTreesClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "Classification Report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "       False       0.93      0.95      0.94       443\n",
    "        True       0.53      0.44      0.48        57\n",
    "\n",
    "    accuracy                           0.89       500\n",
    "   macro avg       0.73      0.69      0.71       500\n",
    "weighted avg       0.88      0.89      0.89       500\n",
    "\n",
    "Confusion Matrix:\n",
    " [[421  22]\n",
    " [ 32  25]]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f511a426b1cd95c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
